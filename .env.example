# ─── Obelisk Core Configuration ─────────────────────────────
# Copy this file to .env and fill in the values you need.
# All values have sensible defaults for local development.

# ─── Inference Service ──────────────────────────────────────
# The Python inference service hosts the LLM model.

# Bind address and port for the inference service
INFERENCE_HOST=127.0.0.1
INFERENCE_PORT=7780

# URL that agents/execution engine use to reach the inference service
# Local dev:  http://localhost:7780  (default)
# Production: https://inference.theobelisk.ai  (remote GPU server)
# INFERENCE_SERVICE_URL=http://localhost:7780

# Device for model loading (auto-detects: cuda > cpu)
# INFERENCE_DEVICE=cuda

# API key for inference service authentication
# When set, all /v1/* endpoints require this key via:
#   Authorization: Bearer <key>  or  X-API-Key: <key>
# Leave empty to disable auth (local dev).
# INFERENCE_API_KEY=

# Debug mode — enables verbose logging (full prompts, responses, token counts)
# INFERENCE_DEBUG=false

# CORS allowed origins for the inference service.
# Comma-separated list of allowed origins, or "*" to allow all (dev only).
# Leave empty to disable CORS restrictions (default).
# INFERENCE_CORS_ORIGINS=https://example.com,https://app.example.com

# ─── Blockchain Service (Clanker state API) ───────────────────
# URL for the blockchain service (GET /clanker/state, etc.).
# Local dev:  http://localhost:8888  (default in node)
# Production: https://base.theobelisk.ai
# BLOCKCHAIN_SERVICE_URL=http://localhost:8888

# API key for blockchain service. When set on the service, send via Authorization: Bearer <key> or X-API-Key. Same value as BLOCKCHAIN_SERVICE_API_KEY on the blockchain-service .env.
# BLOCKCHAIN_SERVICE_API_KEY=

# ─── Scheduler ─────────────────────────────────────────────
# Main-loop scheduler interval in seconds. A Text node containing
# {{process.env.SCHEDULER_INTERVAL_S}} is wired to the scheduler's
# min_seconds / max_seconds inputs. If unset, the scheduler falls back
# to the numeric defaults in workflow metadata (see scheduler.ts:
# meta.min_seconds ?? meta.interval_seconds ?? 60).
# SCHEDULER_INTERVAL_S=60

# ─── Trading Guards ──────────────────────────────────────────
# Cooldown period (minutes) before the bot can re-buy a token it
# recently bought or sold. Prevents re-entering losing positions.
# A Text node containing {{process.env.REBUY_COOLDOWN_MINUTES}} is
# wired to the clanker_buy node. Default: 30
# REBUY_COOLDOWN_MINUTES=30

# ─── Telegram ───────────────────────────────────────────────
# Default Telegram bot credentials for development.
# In production, pass these as environment variables when deploying agents.

# TELEGRAM_DEV_AGENT_BOT_TOKEN=your_bot_token
# TELEGRAM_CHAT_ID=-your_chat_id
