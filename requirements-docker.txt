# Obelisk Agent â€“ Docker (Slim) Requirements
# ~300-400MB image vs ~2.5GB with full ML stack
#
# This file is for the Docker agent container that runs workflows.
# Inference is handled by the standalone inference service (not in this container),
# so torch, transformers, peft, accelerate, bitsandbytes are NOT needed here.
#
# For the full dev/inference-service requirements, see requirements.txt

# API server
fastapi>=0.100.0
uvicorn>=0.23.0
pydantic>=2.0.0

# HTTP client (InferenceClient calls the inference service)
requests>=2.31.0

# Memory management (REQUIRED - no fallback)
langchain>=1.0.0
langchain-core>=1.0.0

# Storage (Supabase for prod mode)
supabase>=1.0.0

# Utilities
python-dotenv>=1.0.0
click>=8.0.0
rich>=13.0.0
numpy>=1.24.0

# Testing
pytest>=7.0.0
