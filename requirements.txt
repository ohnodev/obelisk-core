# Obelisk Inference Service Requirements
# This file covers the standalone inference server (src/inference/).
# The core execution engine and agent runtime are now TypeScript (ts/).
#
# Install:
#   python3 -m venv venv && source venv/bin/activate
#   pip install -r requirements.txt

# PyTorch and Transformers (LLM inference)
torch>=2.0.0,<3
transformers>=4.30.0,<5
accelerate>=0.20.0,<1
bitsandbytes>=0.41.0,<1

# API server
fastapi>=0.100.0,<1
uvicorn>=0.23.0,<1
pydantic>=2.0.0,<3

# Utilities
python-dotenv>=1.0.0,<2
numpy>=1.24.0,<2
